{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "source": [
    "# Predicting the effects of Genetic Variations using Light GBM\n",
    "In this notebook, we will use Light GBM as out algorithm for classifying genetic mutations based on clinical evidence. There are 9 different classes a genetic mutation can be classified based upon.\n",
    "**Light GBM - Some basic information:**\n",
    "* A decision tree based algorithm, LGBM splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. \n",
    "* Advantages:\n",
    "    * Faster training speed and higher accuracy.\n",
    "    * Compatible with huge datasets.\n",
    "    * Better than XGBoost and other boosting algorithms.   \n",
    "* Let's start this kernel!   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb5a516c885fb10174c9d91dc9ec104912d738ff"
   },
   "source": [
    "**(1). Importing all the necessary modules:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREDICTING THE EFFECTS OF GENETIC VARIATIONS USING LGBM\n",
    "# BY - OMKAR SABNIS - 29-05-2018\n",
    "#Importing library\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score,train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27c6b6795463c814929a23ab3764b08e7d804279"
   },
   "source": [
    "**(2). Reading and Visualizing the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "9c827c857e5755f88ccd82e3866f4edff0c91be0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READING THE DATASETS\n",
    "train = pd.read_csv(\"../input/training_variants\")\n",
    "trainx = pd.read_csv('../input/training_text',sep = '\\|\\|', engine= 'python', header=None, \n",
    "                     skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train = pd.merge(train, trainx, how = 'left', on = 'ID').fillna('')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c2314ffe4dd86fa5237d2568f12388d8748a0abb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../input/stage2_test_variants.csv\")\n",
    "testx = pd.read_csv('../input/stage2_test_text.csv',sep = '\\|\\|', engine= 'python', header=None, \n",
    "                     skiprows=1, names=[\"ID\",\"Text\"])\n",
    "test = pd.merge(test, testx, how = 'left', on = 'ID').fillna('')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef68065c85ae451b4d4b349378171920ebcc5df5"
   },
   "source": [
    "**(3). Data Exploration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "1050615c556d5b5fa8d7005d6f901cfbad1cfc0c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.Gene.nunique()\n",
    "train['Gene'].unique()\n",
    "\n",
    "k = train.groupby('Gene')['Gene'].count()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(k, bins=150,log=True)\n",
    "plt.xlabel('Number of times Gene appared')\n",
    "plt.ylabel('Log of count')\n",
    "plt.title('Appearence of gene')\n",
    "plt.show()\n",
    "\n",
    "#count Gene\n",
    "from collections import Counter\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.countplot((train['Gene']))\n",
    "plt.xticks()\n",
    "genecount = Counter(train['Gene'])\n",
    "print('Genes and their appearence:')\n",
    "print(genecount,'\\n',len(genecount))\n",
    "\n",
    "train.Variation.nunique()\n",
    "train['Variation'].unique()\n",
    "\n",
    "k = train.groupby('Variation')['Variation'].count()\n",
    "plt.title('Graph of Gene vs Count')\n",
    "plt.figure(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d43af76563cad8a2a3703170ab1317261767596"
   },
   "source": [
    "**(4). Determining the length of the text:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "14a790289acff32d5a4189abe8ca18bf12916920",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textlen(train):\n",
    "    k = train['Text'].apply(lambda x: len(str(x).split()))\n",
    "    l = train['Text'].apply(lambda x: len(str(x)))\n",
    "    return k, l\n",
    "\n",
    "train['Text_no_word'], train['Text_no_char'] = textlen(train)\n",
    "test['Text_no_word'], test['Text_no_char'] = textlen(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ea4e6c683b227396a516cf9b3c7b0dcef6b2894"
   },
   "source": [
    "**(5). Bag of words and converting the variables into categorical variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a14e4dd6ce4a72567e26b9aeff86f8e1f60da549",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "\tmin_df=1, max_features=1600, strip_accents='unicode',lowercase =True,\n",
    "\tanalyzer='word', token_pattern=r'\\w+', ngram_range=(1, 3), use_idf=True, \n",
    "\tsmooth_idf=True, sublinear_tf=True, stop_words = 'english')\n",
    "X_train = tfidf.fit_transform(train['Text']).toarray()\n",
    "print(X_train)\n",
    "X_test = tfidf.fit_transform(test['Text']).toarray()\n",
    "\n",
    "def encoding(df,col):\n",
    "    le = LabelEncoder()\n",
    "    for i in col:\n",
    "        df[i] = le.fit_transform(df[i])\n",
    "train.columns\n",
    "col = ['Gene', 'Variation', 'Class']\n",
    "encoding(train,col)\n",
    "encoding(test,['Gene', 'Variation'])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train = X_train.join(train[['Gene', 'Variation', 'Text_no_word','Text_no_char']]) \n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test = X_test.join(test[['Gene', 'Variation', 'Text_no_word','Text_no_char']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0775c9fb2eb354252b5b89b9b6934b192bf02335"
   },
   "source": [
    "**(6). Feature Scaling:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "a01ba221613c19772de02d5dfc154b371c52a7a0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FEATURE SCALING\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "y_train = train['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a56a18672332ae41ee397b5c32918ca23e33195"
   },
   "source": [
    "**(7). Splitting the Dataset into training and testing set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6907558314d3de5bd238d22406687b57a9e8c937",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr,xvl,ytr,yvl = train_test_split(X_train,y_train,test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9bc9c2e9d41e5060bc5085e34c301b19f7d200fa"
   },
   "source": [
    "**(8). Modelling - Naive Bayes and Random Forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e2d192e50e464b5f57804e7457e7f846ff2dcf39",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NAIVE BAYES\n",
    "nbc = GaussianNB()\n",
    "nbc.fit(xtr,ytr)\n",
    "y_nbcP = nbc.predict(xvl)\n",
    "y_nbc = nbc.predict_proba(X_test)\n",
    "print(\"Confusion Matrix using Naive Bayes:\")\n",
    "print(confusion_matrix(yvl,y_nbcP))\n",
    "print(\"\\n\")\n",
    "\n",
    "# RANDOM FOREST\n",
    "rfc = RandomForestClassifier(n_estimators=50,max_depth=8,min_samples_split=4)\n",
    "rfc.fit(xtr,ytr)\n",
    "y_rfcp = rfc.predict(xvl)\n",
    "y_rfc=rfc.predict_proba(X_test)\n",
    "print(\"Confusion Matrix using Random Forest:\")\n",
    "print(confusion_matrix(yvl,y_rfcp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20c2a302a9acb425c7ce5c8ebc4dc553009d14e9"
   },
   "source": [
    "**(9). Modelling - Light Gradient Boosting Machine(LGBM):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56cf0596debac43004ea85d16e50f7cee24c2a6e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runLgb(Xtr,Xvl,ytr,yvl,test,num_rounds=10,max_depth=10,eta=0.5,subsample=0.8,\n",
    "           colsample=0.8,min_child_weight=1,early_stopping_rounds=50,seeds_val=2017):\n",
    "    \n",
    "    param = {'task': 'train',\n",
    "             'boosting_type': 'gbdt',\n",
    "             'objective':'multiclass',\n",
    "             'num_class':9,\n",
    "             'learning_rate':eta,\n",
    "             'metric':{'multi_logloss'},\n",
    "             'max_depth':max_depth,\n",
    "             #'min_child_weight':min_child_weight,\n",
    "             'bagging_fraction':subsample,\n",
    "             'feature_fraction':colsample,\n",
    "             'bagging_seed':seeds_val,\n",
    "             'num_iterations': num_rounds, \n",
    "             'num_leaves': 95,           \n",
    "             'min_data_in_leaf': 60, \n",
    "             'lambda_l1': 1.0,\n",
    "             'verbose':10,\n",
    "             'nthread':-1}\n",
    "    lgtrain = lgb.Dataset(Xtr,label=ytr)\n",
    "    lgval = lgb.Dataset(Xvl,label=yvl)\n",
    "    model = lgb.train(param,lgtrain,num_rounds,valid_sets=lgval,\n",
    "                      early_stopping_rounds=early_stopping_rounds,verbose_eval=20)\n",
    "    pred_val = model.predict(Xvl,num_iteration = model.best_iteration)\n",
    "    pred_test = model.predict(test,num_iteration=model.best_iteration)\n",
    "    return pred_test,pred_val,model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd4e99b5a01ea3885d104c2bbbe8baffdd899c8e"
   },
   "source": [
    "**(10). K- Fold Cross Validation of Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a88c9f14687ca8d9074fffddf0ad260b0689732",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,random_state=111,shuffle=True)\n",
    "cv_score = []\n",
    "pred_test_full=0\n",
    "\n",
    "for train_index,test_index in kf.split(X_train):\n",
    "    Xtr,Xvl = X_train[train_index],X_train[test_index]\n",
    "    ytr,yvl = y_train[train_index],y_train[test_index]\n",
    "    \n",
    "    pred_test,pred_val,model = runLgb(Xtr,Xvl,ytr,yvl,X_test,num_rounds=10,max_depth=3,\n",
    "                            eta=0.02,)\n",
    "    pred_test_full +=pred_test\n",
    "pred_test = pred_test_full/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e56bd7af7a1bfb20c4ef46b398ba10b8333d2b59",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUBMISSION OF FILE IN CSV FORMAT:\n",
    "submit = pd.DataFrame(test.ID)\n",
    "submit = submit.join(pd.DataFrame(pred_test))\n",
    "submit.columns = ['ID', 'class1','class2','class3','class4','class5','class6','class7','class8','class9']\n",
    "submit.to_csv('submission.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
